<!DOCTYPE HTML>
<!--
  Based on
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117339330-4"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117339330-4');
    </script>

    <title>
      A Disentangling Invertible Interpretation Network for Explaining Latent
      Representations
    </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="landing">

		<!-- Banner -->
			<section id="banner">
        <h2>
          A Disentangling Invertible Interpretation Network for <br/>
          Explaining Latent Representations
        </h2>
        <p>
        <a href="https://github.com/pesser">Patrick Esser</a>&ast;, 
        <a href="https://github.com/rromb">Robin Rombach</a>&ast;,
        <a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer">Bj&ouml;rn Ommer</a><br/>
        <a href="https://www.iwr.uni-heidelberg.de/">IWR, Heidelberg University</a><br/>
        <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a></p>
			</section>

			<!-- One -->
				<section id="one" class="wrapper style1">
					<div class="container 75%">
						<div class="row 200%">
							<div class="6u 12u$(medium) vert-center" style="margin:1% 0">
                  <div class="container 25%">

                    <div class="image fit captioned align-left"
                                style="margin-bottom:2em; box-shadow:0 0;
                                text-align:justify">
                      <img src="images/overview.jpg" alt="" style="border:0px solid black"/>
                      Our Invertible Interpretation Network <var>T</var> can be applied
                      to arbitrary existing models. Its invertibility
                      guarantees that the translation from <var>z</var> to
                      <var>z&#771;</var> does
                      not affect the performance of the model to be
                      interpreted.
                    </div>

                    <div class="image fit captioned align-center"
                                style="margin-bottom:0em; box-shadow:0 0">
                      <a href="https://arxiv.org/">
                        <img src="images/paper.jpg" alt="" style="border:1px solid black"/>
                      </a>
                      <a href="https://arxiv.org/">arXiv</a>
                      <div class="headerDivider"></div>
                      <a href="images/iin.bib">BibTeX</a>
                      <div class="headerDivider"></div>
                      <a href="https://github.com/CompVis/iin">GitHub</a>
                      <br/>
                      &ast; equal contribution
                    </div>

                  </div>
							</div>
							<div class="6u$ 12u$(medium)">
                <h1>Abstract</h1>
                <p style="text-align: justify">
Neural networks have greatly boosted performance in computer vision by learning
powerful representations of input data. The drawback of end-to-end training for
maximal overall performance are black-box models whose hidden representations
are lacking interpretability: Since distributed coding is optimal for latent
layers to improve their robustness, attributing meaning to parts of a hidden
feature vector or to individual neurons is hindered.  We formulate
interpretation as a translation of hidden representations onto semantic
concepts that are comprehensible to the user. The mapping between both domains
has to be bijective so that semantic modifications in the target domain
correctly alter the original representation. The proposed invertible
interpretation network can be transparently applied on top of existing
architectures with no need to modify or retrain them.  Consequently, we
translate an original representation to an equivalent yet interpretable one and
backwards without affecting the expressiveness and performance of the original.
The invertible interpretation network disentangles the hidden representation
into separate, semantically meaningful concepts. Moreover, we present an
efficient approach to define semantic concepts by only sketching two images and
also an unsupervised strategy. Experimental evaluation demonstrates the wide
applicability to interpretation of existing classification and image generation
networks as well as to semantically guided image manipulation.
                </p>
							</div>
						</div>
					</div>
				</section>

			<!-- Two -->
				<section id="two" class="wrapper style2 special">
					<div class="container">
						<header class="major">
							<h2>Results</h2>
							<p>and applications of our model.</p>
						</header>

            __TEMPLATE_STRING__

				  </div>
				</section>


			<!-- Four -->
				<section id="four" class="wrapper style3 special">
					<div class="container">
						<header class="major">
							<h2>Acknowledgement</h2>
              <p>
              This work has been supported in part by the German federal ministry BMWi within
              the project <q>KI Absicherung</q>, the German Research Foundation (DFG) projects
              371923335 and 421703927, and a hardware donation from NVIDIA corporation.
              This page is based on a design by <a href="http://templated.co">TEMPLATED</a>.
              </p>
						</header>
					</div>
				</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
